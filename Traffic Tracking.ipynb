{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fa8024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "%pip install opencv-python\n",
    "%pip install numpy\n",
    "%pip install ultralytics\n",
    "%pip install lap\n",
    "%pip install shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af524c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from collections import defaultdict\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from shapely.geometry import LineString, Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbc1cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained YOLO model for object detection\n",
    "model = YOLO('model/yolov8customv2.pt', task=\"detect\")\n",
    "\n",
    "# Set the path to the input video file\n",
    "video_path = \"videos/Traffic_3.mp4\"\n",
    "video = cv2.VideoCapture(video_path)  # Initialize video capture object\n",
    "\n",
    "# Dictionary to store the history of object tracks\n",
    "track_history = defaultdict(lambda: [])\n",
    "\n",
    "# Define the points for a counting line\n",
    "line_points = [(1200, 465), (100, 465)]  # Points for a horizontal line\n",
    "\n",
    "# List of class IDs to count (e.g., cars, motorcycles, buses, trucks)\n",
    "classes_to_count = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "\n",
    "# Define the counting line as a Shapely LineString\n",
    "counting_line = LineString(line_points)\n",
    "\n",
    "# Define y-coordinates for additional lines (used for visualization or further analysis)\n",
    "y1 = 420\n",
    "y2 = 510\n",
    "\n",
    "# Initialize counters for vehicles going in different directions\n",
    "south_counts = 0\n",
    "north_counts = 0\n",
    "counting_list = []  # List to track counted vehicle IDs\n",
    "\n",
    "# Loop through frames of the video\n",
    "while video.isOpened():\n",
    "    success, frame = video.read()  # Read a frame from the video\n",
    "\n",
    "    if success:\n",
    "        # Perform object tracking using the YOLO model\n",
    "        results = model.track(frame, persist=True, classes=classes_to_count, show=False)\n",
    "\n",
    "        # Calculate half of the frame width\n",
    "        half_width = frame.shape[1] // 2\n",
    "\n",
    "        # Define points for different lines on the frame\n",
    "        line_points_left1 = [(0, y1), (half_width, y1)]  # Left line 1 (color: red)\n",
    "        line_points_left2 = [(half_width, y1), (frame.shape[1], y1)]  # Left line 2 (color: blue)\n",
    "        line_points_right1 = [(0, y2), (half_width, y2)]  # Right line 1 (color: green)\n",
    "        line_points_right2 = [(half_width, y2), (frame.shape[1], y2)]  # Right line 2 (color: yellow)\n",
    "\n",
    "        # Get detected bounding boxes and their respective track IDs\n",
    "        boxes = results[0].boxes.xywh.cpu()  # Convert to CPU\n",
    "        track_ids = results[0].boxes.id.int().cpu().tolist()  # Convert to list\n",
    "\n",
    "        # Visualize the detection results on the frame\n",
    "        frame = results[0].plot()\n",
    "\n",
    "        # Iterate through each detected object\n",
    "        for box, track_id in zip(boxes, track_ids):\n",
    "            x, y, w, h = box  # Get bounding box coordinates\n",
    "            track = track_history[track_id]  # Retrieve the tracking history for the object\n",
    "            track.append((float(x), float(y)))  # Append the current position to the track history\n",
    "            if len(track) > 5:  # Limit the tracking history to the last 5 points\n",
    "                track.pop(0)\n",
    "\n",
    "            # Calculate speed and direction if the object has been tracked for at least two frames\n",
    "            if len(track) >= 2:\n",
    "                current_pos = np.array(track[-1])\n",
    "                previous_pos = np.array(track[-2])\n",
    "                speed = np.linalg.norm(current_pos - previous_pos)  # Calculate speed\n",
    "\n",
    "                # Calculate the direction based on the bounding box contour\n",
    "                contour = np.array([[int(x), int(y)], [int(x + w), int(y)], [int(x + w), int(y + h)], [int(x), int(y + h)]])\n",
    "                rect = cv2.minAreaRect(contour)  # Get the minimum area rectangle for the contour\n",
    "                angle = rect[2]  # Get the angle of the rectangle\n",
    "\n",
    "                # Determine direction based on vertical movement\n",
    "                direction = \"North\" if current_pos[1] < previous_pos[1] else \"South\"\n",
    "\n",
    "                # Calculate the distance to the counting line\n",
    "                distance = Point(track[-1]).distance(counting_line)\n",
    "                if distance < 15:  # If the object is close to the line\n",
    "                    if track_id not in counting_list:  # Check if the object has already been counted\n",
    "                        counting_list.append(track_id)  # Mark the object as counted\n",
    "                        if box[0] < counting_line.centroid.x:\n",
    "                            north_counts += 1  # Increment northbound count\n",
    "                        else:\n",
    "                            south_counts += 1  # Increment southbound count\n",
    "\n",
    "                # Prepare text for vehicle counts\n",
    "                south_text = 'Southbound vehicles : ' + f'{south_counts}'\n",
    "                north_text = 'Northbound Vehicles : ' + f'{north_counts}'\n",
    "\n",
    "                # Display counts on the frame\n",
    "                cv2.putText(frame, south_text, (950, 50),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)\n",
    "                cv2.putText(frame, north_text, (100, 50),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)\n",
    "\n",
    "                # Display speed and direction on the frame\n",
    "                cv2.putText(frame, f\"Speed: {speed:.2f} px/frame\", (int(x), int(y) - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "                cv2.putText(frame, f\"Direction: {direction}\", (int(x), int(y) + 20),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "\n",
    "                # Draw the counting line\n",
    "                cv2.polylines(frame, [np.array(line_points, dtype=np.int32)], isClosed=True, color=(255, 255, 255), thickness=1)\n",
    "\n",
    "                # Draw the track history of the objects\n",
    "                points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))\n",
    "                cv2.polylines(frame, [points], isClosed=False, color=(255, 255, 255), thickness=1)\n",
    "                cv2.circle(frame, (int(track[-1][0]), int(track[-1][1])), 2, (255, 255, 255), -1)\n",
    "\n",
    "        # Display the annotated frame\n",
    "        cv2.imshow(\"Traffic Tracking\", frame)\n",
    "\n",
    "        # Break the loop if 'ESC' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == 27:  # Check for 'ESC' key (ASCII Value 27)\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Release the video capture object\n",
    "video.release()\n",
    "\n",
    "# Close the display window\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mi_entorno",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
